{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare runs, choose a model, and deploy using REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "dtype: int64\n",
      "NaN values in X_test: fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "dtype: int64\n",
      "NaN values in y_train: 0\n",
      "NaN values in y_test: 0\n",
      "Training with params:                                \n",
      "{'activation': 'sigmoid', 'batch_size': 64, 'epochs': 3, 'learning_rate': 0.0013480015876999667, 'loss': 'mean_squared_error', 'momentum': 0.4054876249102949, 'optimizer': 'SGD', 'output_activation': 'sigmoid', 'units': 32}\n",
      "Training loss:                                       \n",
      "[1.1722311973571777, 0.7688048481941223, 0.7738295197486877]\n",
      "Test loss (MSE):                                     \n",
      "0.7612419128417969                                   \n",
      "Training with params:                                                          \n",
      "{'activation': 'sigmoid', 'batch_size': 32, 'epochs': 3, 'learning_rate': 0.0026062665718308894, 'loss': 'mean_squared_error', 'momentum': 0.38909519051531005, 'optimizer': 'adam', 'output_activation': 'relu', 'units': 256}\n",
      "Training loss:                                                                 \n",
      "[5.137970447540283, 0.6988604068756104, 0.6803491711616516]                    \n",
      "Test loss (MSE):                                                               \n",
      "0.6609221696853638                                                             \n",
      "Training with params:                                                          \n",
      "{'activation': 'relu', 'batch_size': 32, 'epochs': 3, 'learning_rate': 0.0034275039565641193, 'loss': 'mean_squared_error', 'momentum': 0.16182936755738428, 'optimizer': 'adam', 'output_activation': 'tanh', 'units': 512}\n",
      "Training loss:                                                                 \n",
      "[2.439044237136841, 0.6598023772239685, 0.6890154480934143]                    \n",
      "Test loss (MSE):                                                               \n",
      "0.592081606388092                                                              \n",
      "100%|██████████| 3/3 [00:32<00:00, 10.74s/trial, best loss: 0.592081606388092] \n",
      "Best params: {'activation': np.int64(0), 'batch_size': np.int64(0), 'learning_rate': np.float64(0.0034275039565641193), 'loss': np.int64(0), 'momentum': np.float64(0.16182936755738428), 'optimizer': np.int64(1), 'output_activation': np.int64(1), 'units': np.int64(4)}\n",
      "Best MSE: 0.592081606388092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "# Disable GPU if not available\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check for NaN values in the data\n",
    "print(\"NaN values in X_train:\", np.isnan(X_train).sum())\n",
    "print(\"NaN values in X_test:\", np.isnan(X_test).sum())\n",
    "print(\"NaN values in y_train:\", np.isnan(y_train).sum())\n",
    "print(\"NaN values in y_test:\", np.isnan(y_test).sum())\n",
    "\n",
    "# Handle NaN values if any\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, params):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(params[\"units\"], activation=params[\"activation\"]),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=params[\"optimizer\"], loss=\"mse\")\n",
    "    \n",
    "    # Debugging: Print hyperparameters\n",
    "    print(\"Training with params:\", params)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=params[\"epochs\"], verbose=0)\n",
    "    \n",
    "    # Debugging: Print training loss\n",
    "    print(\"Training loss:\", history.history[\"loss\"])\n",
    "    \n",
    "    mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Debugging: Print test loss\n",
    "    print(\"Test loss (MSE):\", mse)\n",
    "    \n",
    "    # Log the model with MLflow\n",
    "    input_schema = Schema([TensorSpec(np.dtype(np.float64), (-1, X_train.shape[1]))])\n",
    "    output_schema = Schema([TensorSpec(np.dtype(np.float64), (-1, 1))])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "    mlflow.tensorflow.log_model(model, artifact_path=\"model\", signature=signature)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    return {\"loss\": mse, \"status\": STATUS_OK, \"model\": model, \"signature\": signature}\n",
    "\n",
    "def objective(params):\n",
    "    params[\"epochs\"] = 3\n",
    "    result = train_model(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        params\n",
    "    )\n",
    "    if np.isnan(result[\"loss\"]):\n",
    "        result[\"loss\"] = 1e6  # Penalize invalid hyperparameter combinations\n",
    "    return result\n",
    "\n",
    "space = {\n",
    "    \"units\": hp.choice(\"units\", [32, 64, 128, 256, 512]),\n",
    "    \"activation\": hp.choice(\"activation\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "    \"output_activation\": hp.choice(\"output_activation\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "    \"optimizer\": hp.choice(\"optimizer\", [\"SGD\", \"adam\"]),\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.0001, 0.01),  # Reduced upper bound\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"loss\": hp.choice(\"loss\", [\"mean_squared_error\"]),\n",
    "    \"batch_size\": hp.choice(\"batch_size\", [32, 64, 128]),\n",
    "    \"epochs\": 3\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=3,\n",
    "        trials=trials\n",
    "    )\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best params, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"mse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=best_run[\"signature\"])\n",
    "\n",
    "    print(f\"Best params: {best}\")\n",
    "    print(f\"Best MSE: {best_run['loss']}\")\n",
    "\n",
    "# End the run after completion\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'activation': 'relu',\n",
    "#     'batch_size': 32,\n",
    "#     'learning_rate': 0.0034275039565641193,\n",
    "#     'loss': 'mean_squared_error',\n",
    "#     'momentum': 0.16182936755738428,\n",
    "#     'optimizer': 'adam',\n",
    "#     'output_activation': 'tanh',\n",
    "#     'units': 512\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 825.35it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.340846 ],\n",
       "       [7.0023155],\n",
       "       [6.7317724],\n",
       "       [6.0285406],\n",
       "       [6.765732 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/ade621bfd87b4b17a168cc7861b29f88/model'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(X_test[:5])\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
